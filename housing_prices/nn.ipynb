{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = 'data/train.csv'\n",
    "test_file_path = 'data/test.csv'\n",
    "\n",
    "train_data = pd.read_csv(train_file_path)\n",
    "test_data = pd.read_csv(test_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 81) (1459, 80) (2919, 79)\n"
     ]
    }
   ],
   "source": [
    "all_features = pd.concat((train_data.iloc[:, 1:-1], test_data.iloc[:, 1:]))\n",
    "\n",
    "print(train_data.shape, test_data.shape, all_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond',\n",
      "       'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2',\n",
      "       'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
      "       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n",
      "       'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces',\n",
      "       'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n",
      "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal',\n",
      "       'MoSold', 'YrSold'],\n",
      "      dtype='object') 36\n"
     ]
    }
   ],
   "source": [
    "numeric_features = all_features.dtypes[all_features.dtypes != 'object'].index\n",
    "\n",
    "print(numeric_features, len(numeric_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标准化数值特征\n",
    "all_features[numeric_features] = all_features[numeric_features].apply(\n",
    "    lambda x: (x - x.mean()) / (x.std()))\n",
    "\n",
    "all_features[numeric_features] = all_features[numeric_features].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2919, 330)\n"
     ]
    }
   ],
   "source": [
    "all_features = pd.get_dummies(all_features, dummy_na=True).astype('float32')\n",
    "print(all_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0673, -0.1844, -0.2178,  ...,  1.0000,  0.0000,  0.0000],\n",
      "        [-0.8735,  0.4581, -0.0720,  ...,  1.0000,  0.0000,  0.0000],\n",
      "        [ 0.0673, -0.0559,  0.1372,  ...,  1.0000,  0.0000,  0.0000],\n",
      "        [ 0.3025, -0.3986, -0.0784,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0673,  0.6294,  0.5188,  ...,  1.0000,  0.0000,  0.0000]]) tensor([[12.2477],\n",
      "        [12.1090],\n",
      "        [12.3172],\n",
      "        [11.8494],\n",
      "        [12.4292]])\n",
      "torch.Size([1460, 330]) torch.Size([1460, 1]) torch.Size([1459, 330])\n"
     ]
    }
   ],
   "source": [
    "n_train = train_data.shape[0]\n",
    "X_train = torch.tensor(all_features[:n_train].values, dtype=torch.float32)\n",
    "X_test = torch.tensor(all_features[n_train:].values, dtype=torch.float32)\n",
    "y_train = torch.tensor(train_data.SalePrice.values, dtype=torch.float32).view(-1, 1)\n",
    "y_train = torch.log(y_train)\n",
    "\n",
    "print(X_train[:5], y_train[:5])\n",
    "print(X_train.shape, y_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立 torch 的 Dataset 和 DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        assert len(X) == len(y)\n",
    "        self.X, self.y = X, y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: torch.Size([64, 330])\n",
      "Shape of y: torch.Size([64, 1])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TrainDataset(X_train, y_train)\n",
    "\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for X, y in train_dataloader:\n",
    "  print(f\"Shape of X: {X.shape}\")\n",
    "  print(f\"Shape of y: {y.shape}\")\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "NeuralNetwork(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=330, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=1024, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=1024, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=64, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.mps.is_available() else 'cpu')\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(len(all_features.columns), 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "        )\n",
    "        # self.linear_relu_stack = nn.Sequential(\n",
    "        #     nn.Linear(X_train.shape[1], 1),\n",
    "        # )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        price = self.linear_relu_stack(x)\n",
    "        return price\n",
    "    \n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 146.960281  [   64/ 1460]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.164440  [   64/ 1460]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.686973  [   64/ 1460]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.065881  [   64/ 1460]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.035463  [   64/ 1460]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.041017  [   64/ 1460]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.027945  [   64/ 1460]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.030017  [   64/ 1460]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.022869  [   64/ 1460]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.021360  [   64/ 1460]\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.016145  [   64/ 1460]\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.018803  [   64/ 1460]\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.009690  [   64/ 1460]\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.013684  [   64/ 1460]\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.009672  [   64/ 1460]\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.007519  [   64/ 1460]\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.006792  [   64/ 1460]\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.007588  [   64/ 1460]\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.006283  [   64/ 1460]\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.009870  [   64/ 1460]\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.007062  [   64/ 1460]\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.005164  [   64/ 1460]\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.005616  [   64/ 1460]\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.007852  [   64/ 1460]\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.005605  [   64/ 1460]\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.005397  [   64/ 1460]\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.004906  [   64/ 1460]\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.007431  [   64/ 1460]\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.007832  [   64/ 1460]\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.004196  [   64/ 1460]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.003790  [   64/ 1460]\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.006862  [   64/ 1460]\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.005876  [   64/ 1460]\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.007960  [   64/ 1460]\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.004219  [   64/ 1460]\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.004642  [   64/ 1460]\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.003778  [   64/ 1460]\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.005971  [   64/ 1460]\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.003468  [   64/ 1460]\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.004691  [   64/ 1460]\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.002436  [   64/ 1460]\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.004378  [   64/ 1460]\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.001988  [   64/ 1460]\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.004115  [   64/ 1460]\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.002498  [   64/ 1460]\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.002471  [   64/ 1460]\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.001985  [   64/ 1460]\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.001386  [   64/ 1460]\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.006442  [   64/ 1460]\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.003409  [   64/ 1460]\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.005969  [   64/ 1460]\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.002233  [   64/ 1460]\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.002427  [   64/ 1460]\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.003662  [   64/ 1460]\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.003507  [   64/ 1460]\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.008546  [   64/ 1460]\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.007110  [   64/ 1460]\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.006202  [   64/ 1460]\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.003603  [   64/ 1460]\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.008041  [   64/ 1460]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.002156  [   64/ 1460]\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.005558  [   64/ 1460]\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.001431  [   64/ 1460]\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.001996  [   64/ 1460]\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.002525  [   64/ 1460]\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.001991  [   64/ 1460]\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.001852  [   64/ 1460]\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.001642  [   64/ 1460]\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.001170  [   64/ 1460]\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.001354  [   64/ 1460]\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.002931  [   64/ 1460]\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.003136  [   64/ 1460]\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.004153  [   64/ 1460]\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.022908  [   64/ 1460]\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.028400  [   64/ 1460]\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.016937  [   64/ 1460]\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.020218  [   64/ 1460]\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.005681  [   64/ 1460]\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.004732  [   64/ 1460]\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.005557  [   64/ 1460]\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.004207  [   64/ 1460]\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.004117  [   64/ 1460]\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.017045  [   64/ 1460]\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.020319  [   64/ 1460]\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.010019  [   64/ 1460]\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.014439  [   64/ 1460]\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.083655  [   64/ 1460]\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.029274  [   64/ 1460]\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.013427  [   64/ 1460]\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.007177  [   64/ 1460]\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.004835  [   64/ 1460]\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.003542  [   64/ 1460]\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.002858  [   64/ 1460]\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.003701  [   64/ 1460]\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.002713  [   64/ 1460]\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.001797  [   64/ 1460]\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.004155  [   64/ 1460]\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.001670  [   64/ 1460]\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.002126  [   64/ 1460]\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.001698  [   64/ 1460]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 12.289767265319824, Actual: 12.24769401550293\n",
      "Predicted: 12.160289764404297, Actual: 12.109010696411133\n",
      "Predicted: 12.259357452392578, Actual: 12.317166328430176\n",
      "Predicted: 11.930134773254395, Actual: 11.849397659301758\n",
      "Predicted: 12.460906982421875, Actual: 12.429216384887695\n",
      "Predicted: 11.758111953735352, Actual: 11.870599746704102\n",
      "Predicted: 12.620908737182617, Actual: 12.634603500366211\n",
      "Predicted: 12.223823547363281, Actual: 12.206072807312012\n",
      "Predicted: 11.797599792480469, Actual: 11.774519920349121\n",
      "Predicted: 11.706730842590332, Actual: 11.67844009399414\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    train_pred = model(X_train[:10])\n",
    "    for i in range(10):\n",
    "        print(f\"Predicted: {train_pred[i].item()}, Actual: {y_train[i].item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_pred = torch.exp(model(X_test))\n",
    "    submission = pd.DataFrame({'Id': test_data['Id'], 'SalePrice': test_pred.cpu().numpy().flatten()})\n",
    "    submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
